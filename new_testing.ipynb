{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "/users/wangtony/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pyfaidx\n",
    "import math\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import deepdish\n",
    "import pyBigWig\n",
    "import scipy\n",
    "from modisco.visualization import viz_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import logomaker\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = pyfaidx.Fasta('/users/surag/genomes/mm10/mm10.fa')\n",
    "seqs = np.load(\"/mnt/lab_data3/surag/kundajelab/playground/src/analyses/20220427_hit_scoring_NN/out/native_shap/shap.npy\")\n",
    "labels = joblib.load(\"/mnt/lab_data3/surag/kundajelab/playground/src/analyses/20220427_hit_scoring_NN/out/native_shap/labels.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = np.zeros((84849,2114,11)) \n",
    "counter = 0 \n",
    "for i in labels: \n",
    "    length = len(i)\n",
    "    for x in range(length): \n",
    "        array = i[x]\n",
    "        motif_class = array[0]\n",
    "        seq_start = array[1]\n",
    "        seq_end = array[2]\n",
    "        for y in range(2114): \n",
    "            if y != seq_start: \n",
    "                encoded_labels[counter][y][10] = 1\n",
    "            else: \n",
    "                encoded_labels[counter][seq_start][motif_class] = 1 \n",
    "    counter = counter + 1\n",
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle the Dataset and Create 8:1:1 Train Val Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.array(range(seqs.shape[0]))\n",
    "np.random.shuffle(idxs)\n",
    "train_idxs = idxs[:int(0.8*len(idxs))]\n",
    "val_idxs = idxs[int(0.8*len(idxs)):int(0.9*len(idxs))]\n",
    "test_idxs = idxs[int(0.9*len(idxs)):]\n",
    "\n",
    "train_seqs = seqs[train_idxs]\n",
    "train_labels = encoded_labels[train_idxs]\n",
    "\n",
    "val_seqs = seqs[val_idxs]\n",
    "val_labels = encoded_labels[val_idxs]\n",
    "\n",
    "test_seqs = seqs[test_idxs]\n",
    "test_labels = encoded_labels[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3conv(channels=50, blocks=8):\n",
    "    inp = tf.keras.Input((2114,4))\n",
    "    x = tf.keras.layers.Conv1D(channels, 20, padding='same', activation='relu')(inp)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    \n",
    "    for i in range(blocks):\n",
    "        x1 = tf.keras.layers.Conv1D(channels, 15, padding='same', activation='relu')(x)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "        x1 = tf.keras.layers.Dropout(0.2)(x1)\n",
    "        x = tf.keras.layers.Add()([x,x1])\n",
    "    \n",
    "    x = tf.keras.layers.Dense(11)(x)\n",
    "    \n",
    "\n",
    "    return tf.keras.Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_3conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2114, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 2114, 50)     4050        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2114, 50)    200         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2114, 50)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 2114, 50)     37550       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2114, 50)    200         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 2114, 50)     0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 2114, 50)     37550       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2114, 50)    200         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2114, 50)     0           ['add[0][0]',                    \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 2114, 50)     37550       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2114, 50)    200         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2114, 50)     0           ['add_1[0][0]',                  \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 2114, 50)     37550       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2114, 50)    200         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 2114, 50)     0           ['add_2[0][0]',                  \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 2114, 50)     37550       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 2114, 50)    200         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 2114, 50)     0           ['add_3[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 2114, 50)     37550       ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 2114, 50)    200         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 2114, 50)     0           ['add_4[0][0]',                  \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 2114, 50)     37550       ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2114, 50)    200         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 2114, 50)     0           ['add_5[0][0]',                  \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 2114, 50)     37550       ['add_6[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 2114, 50)    200         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 2114, 50)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 2114, 50)     0           ['add_6[0][0]',                  \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2114, 11)     561         ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 306,811\n",
      "Trainable params: 305,911\n",
      "Non-trainable params: 900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downweight the Loss for Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_loss_wrapper(background_weight=0.1,background_labels_index=-1):\n",
    "    print(\"background_weight: \",background_weight)\n",
    "    def motif_loss(y_true,logits):\n",
    "        eps=1e-5\n",
    "        y_pred = tf.nn.softmax(logits, axis=-1)\n",
    "        num_classes = y_pred.shape[-1]\n",
    "        cce_loss = -num_classes*(y_true*tf.math.log(y_pred+eps))\n",
    "        weight_vector = [1] * num_classes\n",
    "        weight_vector[background_labels_index] = background_weight\n",
    "        weight_vector = np.array(weight_vector)\n",
    "        weighted_cce_loss = cce_loss * weight_vector\n",
    "        return tf.math.reduce_mean(weighted_cce_loss) * 100\n",
    "    return motif_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background_weight:  0.1\n",
      "Epoch 1/50\n",
      "531/531 [==============================] - 209s 382ms/step - loss: 1.2354 - categorical_accuracy: 0.9884 - acc_within_nonbg: 0.5043 - val_loss: 0.2217 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.1700 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "531/531 [==============================] - 201s 379ms/step - loss: 0.0933 - categorical_accuracy: 0.9991 - acc_within_nonbg: 0.8136 - val_loss: 0.2994 - val_categorical_accuracy: 0.9972 - val_acc_within_nonbg: 0.9888 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "531/531 [==============================] - 199s 376ms/step - loss: 0.0605 - categorical_accuracy: 0.9994 - acc_within_nonbg: 0.8666 - val_loss: 0.0403 - val_categorical_accuracy: 0.9994 - val_acc_within_nonbg: 0.9663 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "531/531 [==============================] - 199s 375ms/step - loss: 0.0512 - categorical_accuracy: 0.9994 - acc_within_nonbg: 0.8848 - val_loss: 0.0572 - val_categorical_accuracy: 0.9990 - val_acc_within_nonbg: 0.9831 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "531/531 [==============================] - 199s 375ms/step - loss: 0.0472 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.8894 - val_loss: 0.0392 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9214 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "531/531 [==============================] - 199s 375ms/step - loss: 0.0709 - categorical_accuracy: 0.9992 - acc_within_nonbg: 0.8480 - val_loss: 0.0438 - val_categorical_accuracy: 0.9993 - val_acc_within_nonbg: 0.9566 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0548 - categorical_accuracy: 0.9994 - acc_within_nonbg: 0.8766 - val_loss: 0.0369 - val_categorical_accuracy: 0.9994 - val_acc_within_nonbg: 0.9699 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0425 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.9014 - val_loss: 0.0330 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9669 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0402 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.9057 - val_loss: 0.0316 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9674 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0387 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.9103 - val_loss: 0.0317 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9674 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0382 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.9107 - val_loss: 0.0327 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9747 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0378 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.9138 - val_loss: 0.0312 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9748 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0360 - categorical_accuracy: 0.9995 - acc_within_nonbg: 0.9187 - val_loss: 0.0304 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0354 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9194 - val_loss: 0.0294 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9702 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0349 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9217 - val_loss: 0.0292 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9746 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0345 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9231 - val_loss: 0.0292 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9742 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0340 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9258 - val_loss: 0.0282 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9737 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0335 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9266 - val_loss: 0.0288 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0329 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9277 - val_loss: 0.0272 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0325 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9282 - val_loss: 0.0286 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0319 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9313 - val_loss: 0.0285 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0315 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9319 - val_loss: 0.0264 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9745 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0309 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9330 - val_loss: 0.0275 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0298 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9341 - val_loss: 0.0270 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0292 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9354 - val_loss: 0.0262 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9748 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0288 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9375 - val_loss: 0.0270 - val_categorical_accuracy: 0.9995 - val_acc_within_nonbg: 0.9811 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0285 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9374 - val_loss: 0.0259 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0281 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9405 - val_loss: 0.0254 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0280 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9403 - val_loss: 0.0251 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0276 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9427 - val_loss: 0.0251 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0273 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9433 - val_loss: 0.0247 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0270 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9457 - val_loss: 0.0245 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9801 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0267 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9462 - val_loss: 0.0235 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0266 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9472 - val_loss: 0.0242 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0261 - categorical_accuracy: 0.9996 - acc_within_nonbg: 0.9489 - val_loss: 0.0238 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0259 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9496 - val_loss: 0.0243 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9835 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0257 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9511 - val_loss: 0.0229 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0254 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9520 - val_loss: 0.0234 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9816 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0254 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9523 - val_loss: 0.0232 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9813 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "531/531 [==============================] - 198s 373ms/step - loss: 0.0251 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9532 - val_loss: 0.0226 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0248 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9548 - val_loss: 0.0230 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0247 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9548 - val_loss: 0.0229 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9806 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0246 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9557 - val_loss: 0.0230 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0244 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9563 - val_loss: 0.0220 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0242 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9567 - val_loss: 0.0221 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0241 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9576 - val_loss: 0.0222 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9805 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0239 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9583 - val_loss: 0.0221 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "531/531 [==============================] - 199s 374ms/step - loss: 0.0238 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9596 - val_loss: 0.0224 - val_categorical_accuracy: 0.9996 - val_acc_within_nonbg: 0.9830 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0237 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9604 - val_loss: 0.0216 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9767 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "531/531 [==============================] - 198s 374ms/step - loss: 0.0234 - categorical_accuracy: 0.9997 - acc_within_nonbg: 0.9608 - val_loss: 0.0217 - val_categorical_accuracy: 0.9997 - val_acc_within_nonbg: 0.9804 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25cfedfcf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_3conv()\n",
    "# cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "def acc_within_nonbg(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(tf.math.argmax(y_true, -1), tf.math.argmax(y_pred, -1))[tf.math.argmax(y_true, -1) != 10],\n",
    "                                  tf.float32))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=motif_loss_wrapper(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy(), acc_within_nonbg],\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc_within_nonbg', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)\n",
    "model.fit(train_seqs,\n",
    "          train_labels,\n",
    "         batch_size=128,\n",
    "         epochs=50,\n",
    "         validation_data=(val_seqs, val_labels),\n",
    "         callbacks=reduce_lr,\n",
    "         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(\"new1_motif_model.hdf5\")\n",
    "# from keras.models import load_model\n",
    "# regularized_keras_model=load_model(\"new_motif_model.hdf5\", custom_objects={\"acc_within_nonbg\": acc_within_nonbg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: motif_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b848ce8fddca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                   tf.float32))\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new1_motif_model.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"acc_within_nonbg\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0macc_within_nonbg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    708\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         raise ValueError(\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0;34mf'Unknown {printable_module_name}: {object_name}. Please ensure '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;34m'this object is passed to the `custom_objects` argument. See '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;34m'https://www.tensorflow.org/guide/keras/save_and_serialize'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function: motif_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "def acc_within_nonbg(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(tf.math.argmax(y_true, -1), tf.math.argmax(y_pred, -1))[tf.math.argmax(y_true, -1) != 10],\n",
    "                                  tf.float32))\n",
    "from keras.models import load_model\n",
    "model2=load_model(\"new1_motif_model.hdf5\", custom_objects={\"acc_within_nonbg\": acc_within_nonbg})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy on Test Set and Visualize Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_seqs)\n",
    "acc_within_nonbg(test_labels, test_pred).numpy()\n",
    "conf_mat = confusion_matrix((np.argmax(test_labels, -1)[np.argmax(test_labels, -1)!=10]).flatten(), \n",
    "                            (np.argmax(test_pred, -1)[np.argmax(test_labels, -1)!=10]).flatten())\n",
    "\n",
    "ax = sns.heatmap(conf_mat, annot=False, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Prediction on Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "IDX=800\n",
    "plt.plot(np.argmax(test_labels[IDX], -1)[np.argmax(test_labels[IDX], -1)!=10], label='label')\n",
    "plt.plot(np.argmax(test_pred[IDX], -1)[np.argmax(test_labels[IDX], -1)!=10], label='pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.argmax(test_labels[IDX], -1), label='label')\n",
    "plt.plot(np.argmax(test_pred[IDX], -1), label='pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX=800\n",
    "fig, ax = plt.subplots(1, figsize=(20,2))\n",
    "logomaker.Logo(pd.DataFrame(test_seqs[IDX][600:1200], columns=['A','C','G','T']), ax=ax)\n",
    "plt.plot(np.argmax(test_labels[IDX][600:1200], -1)/100, label='label')\n",
    "plt.plot(np.argmax(test_pred[IDX][600:1200], -1)/100, label='pred')\n",
    "ax.set_ylim(0,.11)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Prediction on Real Sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HDF5_PATH = \"/oak/stanford/groups/akundaje/projects/cad/outs/10_5_2021_bpnet_training_valid_arch/full_models/c0/fold0.counts_scores.h5\"\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "imp_scores = deepdish.io.load(HDF5_PATH)\n",
    "shap_abssum = np.abs(imp_scores['projected_shap']['seq'][:,:,imp_scores['projected_shap']['seq'].shape[1]//2-250:imp_scores['projected_shap']['seq'].shape[1]//2+250]).sum(1).sum(-1)\n",
    "top = np.random.choice(np.argsort(shap_abssum)[::-1][:20000], 100)\n",
    "top_seq = imp_scores['projected_shap']['seq'][top].transpose(0,2,1)\n",
    "top_pred = model.predict(top_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX=3\n",
    "\n",
    "sns.heatmap(top_pred[IDX][900:1200].T)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(40,2))\n",
    "logomaker.Logo(pd.DataFrame(top_seq[IDX][900:1200], columns=['A','C','G','T']), ax=ax)\n",
    "plt.plot(np.argmax(top_pred[IDX][900:1200,], -1)/100, label='pred')\n",
    "ax.set_ylim(0,.11)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /oak/stanford/groups/akundaje/projects/cad/outs/10_5_2021_bpnet_training_valid_arch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
